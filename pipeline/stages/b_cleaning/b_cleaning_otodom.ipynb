{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def set_project_root():\n",
    "    notebooks_dir = Path.cwd()\n",
    "\n",
    "    project_root = notebooks_dir.parents[2]\n",
    "\n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.append(str(project_root))\n",
    "\n",
    "    return project_root\n",
    "\n",
    "project_root = set_project_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Local imports\n",
    "from pipeline.stages._csv_utils import DataPathCleaningManager\n",
    "from pipeline.config._conf_file_manager import ConfigManager\n",
    "\n",
    "config_file = ConfigManager(\"run_pipeline.conf\")\n",
    "TIMEPLACE = \"MARKET_OFFERS_TIMEPLACE\"\n",
    "data_timeplace = config_file.read_value(TIMEPLACE)\n",
    "if data_timeplace is None:\n",
    "    raise ValueError(F\"The configuration variable {TIMEPLACE} is not set.\")\n",
    "\n",
    "data_path_manager = DataPathCleaningManager(data_timeplace, project_root)\n",
    "\n",
    "df_otodom = data_path_manager.load_df(domain=\"otodom\", is_cleaned=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_percentage(df, column_name):\n",
    "    \"\"\"\n",
    "    Function to calculate the count and percentage of unique values in a given column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to analyze.\n",
    "    column_name (str): The name of the column in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with the count and percentage of each unique value in the specified column.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified column is not found in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Check if the column exists in the DataFrame\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in DataFrame.\")\n",
    "\n",
    "    # Calculate count and normalized values\n",
    "    count = df[column_name].value_counts(dropna=False)\n",
    "    normalized = df[column_name].value_counts(dropna=False, normalize=True) * 100\n",
    "\n",
    "    # Concatenate count and normalized values side by side\n",
    "    result = pd.concat([count, normalized], axis=1)\n",
    "    result.columns = ['Count', 'Percentage']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_comma_separated_values(df, column_name):\n",
    "    \"\"\"\n",
    "    Counts the occurrences of individual elements in a comma-separated string column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the column.\n",
    "    column_name (str): The name of the column to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with the count and percentage of each unique element found in the comma-separated values.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified column is not found in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Check if the column exists in the DataFrame\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in DataFrame.\")\n",
    "\n",
    "    # Split the column values, explode to individual elements, and count\n",
    "    exploded_items = df[column_name].dropna().str.split(', ').explode()\n",
    "    exploded_df = pd.DataFrame({column_name: exploded_items})\n",
    "    counts_and_percent = count_and_percentage(exploded_df, column_name)\n",
    "\n",
    "    return counts_and_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_numeric_characters(df, column_name):\n",
    "    \"\"\"\n",
    "    Removes all non-numeric characters from a column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the column.\n",
    "    column_name (str): The name of the column to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with all non-numeric characters removed from the specified column.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified column is not found in the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    return df[column_name].str.replace('[^a-zA-Z]', '', regex=True).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(str(text).split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otodom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_otodom_data(df: pd.DataFrame):\n",
    "\n",
    "    # 1. Split 'location' into street, city, and voivodeship\n",
    "    df['location_split'] = df['location'].str.split(', ')\n",
    "    df['street'] = df['location_split'].apply(lambda x: x[0] if len(x) > 2 else None)\n",
    "    df['city'] = df['location_split'].apply(lambda x: x[-2] if len(x) > 1 else None)\n",
    "    df['voivodeship'] = df['location_split'].apply(lambda x: x[-1] if x else None)\n",
    "\n",
    "    # Drop the temporary 'location_split' column\n",
    "    df.drop(columns=['location_split'], inplace=True)\n",
    "\n",
    "    # 2. Convert 'price' into float\n",
    "    df['price'] = df['price'].str.replace(' ', '').str.extract('(\\d+)')[0]\n",
    "    df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    df['price'] = df['price'].astype('float64')\n",
    "\n",
    "    # Extract and convert 'square_meters' into integers\n",
    "    df['square_meters'] = df['square_meters'].str.extract('(\\d+)')[0].astype('float64')\n",
    "\n",
    "    # Extract and convert 'rent' into float\n",
    "    df['rent'] = df['rent'].str.extract('(\\d+)')[0]\n",
    "    df['rent'] = pd.to_numeric(df['rent'], errors='coerce').astype('float64')\n",
    "    df['total_rent'] = df['rent'].add(df['price'], fill_value=0).astype('float64')\n",
    "\n",
    "    # Extract and convert 'deposit' into float\n",
    "    df['deposit'] = df['deposit'].str.replace(' ', '').str.extract('(\\d+)')[0]\n",
    "    df['deposit'] = pd.to_numeric(df['deposit'], errors='coerce').astype('float64')\n",
    "\n",
    "    # Convert 'number_of_rooms' into an integer, special handling for \"Kawalerka\"\n",
    "    # https://regex101.com/r/L4a3bp/1\n",
    "    if df['number_of_rooms'].dtype in [np.object, np.str]:\n",
    "        df['number_of_rooms'] = df['number_of_rooms'].replace('Kawalerka', '1')\n",
    "        df['number_of_rooms'] = df['number_of_rooms'].str.replace('\\D', '', regex=True)\n",
    "\n",
    "    df['number_of_rooms'] = df['number_of_rooms'].astype('Int64')\n",
    "\n",
    "    # Extract and clean 'floor_level'\n",
    "    df_split = df['floor_level'].str.split('/', expand=True)\n",
    "    df_split[0] = df_split[0].replace({'parter': 0, 'suterena': -1, '> 10': 11})\n",
    "\n",
    "    poddasze_rows = df_split[0] == 'poddasze'\n",
    "    df_split.loc[poddasze_rows, 0] = (df_split.loc[poddasze_rows, 1].fillna(0).astype(int) + 1).astype(str)\n",
    "\n",
    "    df['attic'] = df_split[0] == 'poddasze'\n",
    "    df['floor'] = pd.to_numeric(df_split[0], errors='coerce')\n",
    "    df['floor'] = df['floor'].astype('Int64')\n",
    "    df['building_floors'] = pd.to_numeric(df_split[1], errors='coerce')\n",
    "    df['building_floors'] = df['building_floors'].astype('Int64')\n",
    "    \n",
    "    del df['floor_level']\n",
    "\n",
    "    # Convert 'elevator' and 'parking_space' into boolean values\n",
    "    df['elevator'] = df['elevator'].map({'tak': True, 'nie': False}).astype('boolean')\n",
    "\n",
    "    df['parking_space'] = df['parking_space'].map({'garaż/miejsce parkingowe': True, 'brak informacji': False}).astype('boolean')\n",
    "    \n",
    "    # Convert 'build_year' into integers\n",
    "    df['build_year'] = pd.to_numeric(df['build_year'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # todo create master columns for subcolumns\n",
    "    # 3. Explode 'equipment', 'media_types', 'heating', 'security', 'windows', 'building_materials', 'additional_information' into boolean categories\n",
    "    def explode_and_get_dummies(column_name):\n",
    "        return df[column_name].str.get_dummies(sep=', ')\n",
    "    \n",
    "    to_explode = ['equipment', 'media_types', 'heating', 'security', 'windows', 'balcony_garden_terrace', 'building_material', 'additional_information']\n",
    "\n",
    "    for column in to_explode:\n",
    "        df = df.join(explode_and_get_dummies(column).add_prefix(f\"{column}_\"))\n",
    "\n",
    "    for column in to_explode:\n",
    "        del df[column]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned = clean_otodom_data(df_otodom)\n",
    "df_otodom_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = [\n",
    "    'link', 'title', 'summary_description', 'remote service', \n",
    "    'price', 'rent', 'total_rent', 'deposit', \n",
    "    'location', 'street', 'city', 'voivodeship', \n",
    "    'square_meters', 'number_of_rooms', 'floor', 'attic', 'building_floors', \n",
    "    'available_from', 'completion', 'ownership', 'rent_to_students', \n",
    "    'building_type', 'build_year', \n",
    "    'elevator', 'parking_space', \n",
    "    'equipment_brak informacji', 'equipment_kuchenka', 'equipment_lodówka', 'equipment_meble', 'equipment_piekarnik', 'equipment_pralka', 'equipment_telewizor', 'equipment_zmywarka', \n",
    "    'media_types_brak informacji', 'media_types_internet', 'media_types_telefon', 'media_types_telewizja kablowa', \n",
    "    'heating_brak informacji', 'heating_elektryczne', 'heating_gazowe', 'heating_inne', 'heating_kotłownia', 'heating_miejskie', 'heating_piece kaflowe', \n",
    "    'security_brak informacji', 'security_domofon / wideofon', 'security_drzwi / okna antywłamaniowe', 'security_monitoring / ochrona', 'security_rolety antywłamaniowe', 'security_system alarmowy', 'security_teren zamknięty', \n",
    "    'windows_aluminiowe', 'windows_brak informacji', 'windows_drewniane', 'windows_plastikowe', \n",
    "    'building_material_beton', 'building_material_beton komórkowy', 'building_material_brak informacji', 'building_material_cegła', 'building_material_drewno', 'building_material_inne', 'building_material_keramzyt', 'building_material_pustak', 'building_material_silikat', 'building_material_wielka płyta', 'building_material_żelbet', \n",
    "    'additional_information_brak informacji', 'additional_information_dwupoziomowe', 'additional_information_klimatyzacja', 'additional_information_oddzielna kuchnia', 'additional_information_piwnica', 'additional_information_pom. użytkowe', 'additional_information_tylko dla niepalących'\n",
    "]\n",
    "\n",
    "# Add missing columns from columns_order with NaN values\n",
    "for column in columns_order:\n",
    "    if column not in df_otodom_cleaned.columns:\n",
    "        df_otodom_cleaned[column] = np.nan\n",
    "        \n",
    "df_otodom_cleaned = df_otodom_cleaned[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_multiindex = [\n",
    "    ('listing', 'link'),\n",
    "    ('listing', 'title'),\n",
    "    ('listing', 'summary_description'),\n",
    "    ('listing', 'remote_service'),\n",
    "    ('pricing', 'price'),\n",
    "    ('pricing', 'rent'),\n",
    "    ('pricing', 'total_rent'),\n",
    "    ('pricing', 'deposit'),\n",
    "    ('location', 'complete_address'),\n",
    "    ('location', 'street'),\n",
    "    ('location', 'city'),\n",
    "    ('location', 'voivodeship'),\n",
    "    ('size', 'square_meters'),\n",
    "    ('size', 'number_of_rooms'),\n",
    "    ('size', 'floor'),\n",
    "    ('size', 'attic'),\n",
    "    ('size', 'building_floors'),\n",
    "    ('legal_and_availability', 'available_from'),\n",
    "    ('legal_and_availability', 'completion'),\n",
    "    ('legal_and_availability', 'ownership'),\n",
    "    ('legal_and_availability', 'rent_to_students'),\n",
    "    ('type_and_year', 'building_type'),\n",
    "    ('type_and_year', 'build_year'),\n",
    "    ('amenities', 'elevator'),\n",
    "    ('amenities', 'parking_space'),\n",
    "    ('equipment', 'no_information'),\n",
    "    ('equipment', 'stove'),\n",
    "    ('equipment', 'fridge'),\n",
    "    ('equipment', 'furniture'),\n",
    "    ('equipment', 'oven'),\n",
    "    ('equipment', 'washing_machine'),\n",
    "    ('equipment', 'TV'),\n",
    "    ('equipment', 'dishwasher'),\n",
    "    ('media_types', 'no_information'),\n",
    "    ('media_types', 'internet'),\n",
    "    ('media_types', 'telephone'),\n",
    "    ('media_types', 'cable_TV'),\n",
    "    ('heating', 'no_information'),\n",
    "    ('heating', 'electric'),\n",
    "    ('heating', 'gas'),\n",
    "    ('heating', 'other'),\n",
    "    ('heating', 'boiler_room'),\n",
    "    ('heating', 'district'),\n",
    "    ('heating', 'tile_stove'),\n",
    "    ('security', 'no_information'),\n",
    "    ('security', 'intercom_or_video_intercom'),\n",
    "    ('security', 'anti_burglary_doors_or_windows'),\n",
    "    ('security', 'monitoring_or_security'),\n",
    "    ('security', 'anti_burglary_roller_blinds'),\n",
    "    ('security', 'alarm_system'),\n",
    "    ('security', 'enclosed_area'),\n",
    "    ('windows', 'aluminum'),\n",
    "    ('windows', 'no_information'),\n",
    "    ('windows', 'wooden'),\n",
    "    ('windows', 'plastic'),\n",
    "    ('building_material', 'concrete'),\n",
    "    ('building_material', 'aerated_concrete'),\n",
    "    ('building_material', 'no_information'),\n",
    "    ('building_material', 'brick'),\n",
    "    ('building_material', 'wood'),\n",
    "    ('building_material', 'other'),\n",
    "    ('building_material', 'lightweight_aggregate'),\n",
    "    ('building_material', 'hollow_brick'),\n",
    "    ('building_material', 'silicate'),\n",
    "    ('building_material', 'large_panel'),\n",
    "    ('building_material', 'reinforced_concrete'),\n",
    "    ('additional_information', 'no_information'),\n",
    "    ('additional_information', 'duplex'),\n",
    "    ('additional_information', 'air_conditioning'),\n",
    "    ('additional_information', 'separate_kitchen'),\n",
    "    ('additional_information', 'basement'),\n",
    "    ('additional_information', 'utility_room'),\n",
    "    ('additional_information', 'non_smokers_only')\n",
    "]\n",
    "\n",
    "multiindex = pd.MultiIndex.from_tuples(columns_multiindex, names=['Category', 'Subcategory'])\n",
    "df_otodom_cleaned.columns = multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Checking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert df_otodom_cleaned[[('pricing', 'price'), ('pricing', 'rent'), ('pricing', 'deposit')]].min().min() >= 0, \"Price, rent, or deposit contains negative values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[[('pricing', 'price'), ('pricing', 'rent'), ('pricing', 'deposit')]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_and_first_percentile(column_name, df):\n",
    "    \"\"\"\n",
    "    Returns the first and last percentile of a column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    column_name (str): The name of the column to analyze.\n",
    "    df (pandas.DataFrame): The DataFrame containing the column.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the first and last percentile of the column.\n",
    "    \"\"\"\n",
    "    return df[column_name].quantile([0.01, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_and_first_percentile(('pricing', 'price'), df_otodom_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_otodom_cleaned.sort_values(by=[('pricing', 'price')], ascending=False).head()[[('listing', 'link'), ('listing', 'title'), ('listing', 'summary_description'), ('pricing', 'total_rent'), ('location', 'city')]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_otodom_cleaned[('location', 'city')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_otodom_cleaned[('location', 'voivodeship')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textual Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('listing', 'summary_description')].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('listing', 'summary_description')].apply(count_words).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max values of the selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('size', 'square_meters')].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('size', 'square_meters')].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('size', 'number_of_rooms')].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('size', 'number_of_rooms')].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('size', 'floor')].value_counts().index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('size', 'building_floors')].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if date column is the date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format_regex = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "\n",
    "# Check if each date in the column matches the format\n",
    "# Perform the assertion directly\n",
    "assert (df_otodom_cleaned[('legal_and_availability', 'available_from')].dropna().str.match(date_format_regex)).all(), \"Not all dates match the required format\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  2.2.3 Translate Polish to English\n",
    "`Listing | title`, `Listing | summary_description` are not translated due to losing context by using a translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('listing', 'remote_service')] = df_otodom_cleaned[('listing', 'remote_service')].map(\n",
    "    {'Obsługa zdalnaZapytaj': np.NaN, \n",
    "     'Obsługa zdalnatak': 'unspecified', \n",
    "     'Obsługa zdalnaFilm': 'video',\n",
    "     'Obsługa zdalnaWirtualny spacer': 'virtual_tour',\n",
    "     'Obsługa zdalnaFilmWirtualny spacer': 'video_virtual_tour',\n",
    "     }\n",
    "    )\n",
    "df_otodom_cleaned[('listing', 'remote_service')].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "legal_and_availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('legal_and_availability', 'completion')] = df_otodom_cleaned[('legal_and_availability', 'completion')].map(\n",
    "    {'do zamieszkania': 'ready_to_move_in', \n",
    "     'do remontu': 'in_need_of_renovation', \n",
    "     'do wykończenia': 'unfinished'}\n",
    "    )\n",
    "df_otodom_cleaned[('legal_and_availability', 'completion')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('legal_and_availability', 'ownership')]= df_otodom_cleaned[('legal_and_availability', 'ownership')].map(\n",
    "    {'biuro nieruchomości': 'real_estate_agency', \n",
    "     'prywatny': 'private', \n",
    "     'deweloper': 'developer'}\n",
    "     )\n",
    "df_otodom_cleaned[('legal_and_availability', 'ownership')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('legal_and_availability', 'rent_to_students')] = df_otodom_cleaned[('legal_and_availability', 'rent_to_students')].map({'brak informacji': np.NaN, 'tak': True, 'nie': False})\n",
    "df_otodom_cleaned[('legal_and_availability', 'rent_to_students')].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type_and_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned['type_and_year'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('type_and_year', 'building_type')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('type_and_year', 'building_type')] = df_otodom_cleaned[('type_and_year', 'building_type')].map({\n",
    "    'blok': 'block_of_flats', \n",
    "    'apartamentowiec': 'apartment_building', \n",
    "    'kamienica': 'historic_apartment_building',\n",
    "    'dom wolnostojący': 'detached_house',\n",
    "    'szeregowiec': 'terraced_house',\n",
    "    })\n",
    "df_otodom_cleaned[('type_and_year', 'building_type')].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('legal_and_availability', 'rent_to_students')] = df_otodom_cleaned[('legal_and_availability', 'rent_to_students')].fillna(False).astype('boolean')\n",
    "df_otodom_cleaned[('legal_and_availability', 'rent_to_students')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned[('legal_and_availability', 'rent_to_students')].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned['equipment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_otodom_cleaned['equipment'].columns:\n",
    "    df_otodom_cleaned[('equipment', col)] = df_otodom_cleaned[('equipment', col)].fillna(0).astype(bool)\n",
    "df_otodom_cleaned['equipment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_otodom_cleaned['media_types'].columns:\n",
    "    df_otodom_cleaned[('media_types', col)] = df_otodom_cleaned[('media_types', col)].fillna(0).astype(bool)\n",
    "df_otodom_cleaned['media_types'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_otodom_cleaned['heating'].columns:\n",
    "    df_otodom_cleaned[('heating', col)] = df_otodom_cleaned[('heating', col)].fillna(0).astype(bool)\n",
    "df_otodom_cleaned['heating'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_otodom_cleaned['security'].columns:\n",
    "    df_otodom_cleaned[('security', col)] = df_otodom_cleaned[('security', col)].fillna(0).astype(bool)\n",
    "df_otodom_cleaned['security'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_otodom_cleaned['windows'].columns:\n",
    "    df_otodom_cleaned[('windows', col)] = df_otodom_cleaned[('windows', col)].fillna(0).astype(bool)\n",
    "df_otodom_cleaned['windows'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_otodom_cleaned['building_material'].columns:\n",
    "    df_otodom_cleaned[('building_material', col)] = df_otodom_cleaned[('building_material', col)].fillna(0).astype(bool)\n",
    "df_otodom_cleaned['building_material'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_otodom_cleaned['additional_information'].columns:\n",
    "    df_otodom_cleaned[('additional_information', col)] = df_otodom_cleaned[('additional_information', col)].fillna(0).astype(bool)\n",
    "df_otodom_cleaned['additional_information'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting selected columns to the strings<br>\n",
    "*We do not care about backward compatibly, and a `string` is much more readable than a `object`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    ('listing', 'link'),\n",
    "    ('listing', 'title'),\n",
    "    ('listing', 'summary_description'),\n",
    "    ('listing', 'remote_service'),\n",
    "    ('location', 'complete_address'),\n",
    "    ('location', 'street'),\n",
    "    ('location', 'city'),\n",
    "    ('location', 'voivodeship'),\n",
    "    ('legal_and_availability', 'available_from'),\n",
    "    ('legal_and_availability', 'completion'),\n",
    "    ('legal_and_availability', 'ownership'),\n",
    "    ('type_and_year', 'building_type'),\n",
    "]\n",
    "\n",
    "# Convert each column to the pandas string type\n",
    "for col in columns_to_convert:\n",
    "    df_otodom_cleaned[col] = df_otodom_cleaned[col].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_cleaned.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_manager.save_df(df_otodom_cleaned, domain=\"otodom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Check saved data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otodom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_otodom_saved = data_path_manager.load_df(domain=\"otodom\", is_cleaned=True)\n",
    "df_otodom_saved.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "are_identical = df_otodom_saved.equals(df_otodom_cleaned)\n",
    "if not are_identical:\n",
    "    raise ValueError(\"The saved DataFrame is not identical to the original one.\")\n",
    "else:\n",
    "    print(\"The saved DataFrame is identical to the original one.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
